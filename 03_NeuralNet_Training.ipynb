{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "\n",
    "- Sum of Squares for Error, SSE\n",
    "- Cross Entropy Error, CEE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSE : Sum of Squares for Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sum_squares_error(y, t) :\n",
    "    return 0.5 * np.sum((y - t) ** 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 2, 신경망 출력도 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n"
     ]
    }
   ],
   "source": [
    "# 신경망의 출력(Softmax Function) -> 확률로 해석 가능\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] \n",
    "# 정답 레이블(one-hot encoding) : 2에 해당하는 원소 값이 1이므로 정답이 '2'임을 알 수 있다\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0 ,0] \n",
    "\n",
    "print(sum_squares_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 2, 신경망 출력은 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5975\n"
     ]
    }
   ],
   "source": [
    "# 신경망의 출력(Softmax Function) -> 확률로 해석 가능\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0] \n",
    "# 정답 레이블(one-hot encoding) : 2에 해당하는 원소 값이 1이므로 정답이 '2'임을 알 수 있다\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0 ,0] \n",
    "\n",
    "print(sum_squares_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CEE : Cross Entropy Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.log()에 0을 입력하면 -inf가 되어 계산을 진행할 수 없기 때문에\n",
    "# 아주 작은 값을 1e-7 == 0.0000001 더해서 0이 되지 않도록 해줘야 한다.\n",
    "def cross_entropy_error(y, t) :\n",
    "    delta = 1e-7 \n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 2, 신경망 출력도 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099338\n"
     ]
    }
   ],
   "source": [
    "# 신경망의 출력(Softmax Function) -> 확률로 해석 가능\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] \n",
    "# 정답 레이블(one-hot encoding) : 2에 해당하는 원소 값이 1이므로 정답이 '2'임을 알 수 있다\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0 ,0] \n",
    "\n",
    "print(cross_entropy_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 2, 신경망 출력은 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "# 신경망의 출력(Softmax Function) -> 확률로 해석 가능\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0] \n",
    "# 정답 레이블(one-hot encoding) : 2에 해당하는 원소 값이 1이므로 정답이 '2'임을 알 수 있다\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0 ,0] \n",
    "\n",
    "print(cross_entropy_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mini-batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape) # 6000만 장의 data 존재(하나의 data는 원래 28 * 28이었는데, flatten=True 때문에)\n",
    "print(t_train.shape) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련데이터, 시험데이터 랜덤 10장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40886 28863 16582 12850 39739 20213 54499 59357 50002 59470]\n"
     ]
    }
   ],
   "source": [
    "train_size = x_train.shape[0] # 60,000장의 사진(데이터)\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "print(batch_mask) #  10개 data의 index번호 random하게 뽑기\n",
    "\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch용 CEE(Cross Entropy Error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정답 레이블이 one-hot encoding일 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y : 신경망 출력, t : 정답 레이블\n",
    "# 데이터 하나당 Cross Entropy를 구하는 경우는 데이터의 형상을 바꿔준다.\n",
    "def cross_entropy_error(y, t) :\n",
    "    if y.ndim == 1 :\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정답 레이블이 숫자 레이블로 주어졌을 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y : 신경망 출력, t : 정답 레이블\n",
    "# 데이터 하나당 Cross Entropy를 구하는 경우는 데이터의 형상을 바꿔준다.\n",
    "def cross_entropy_error(y, t) :\n",
    "    if y.ndim == 1 :\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "# 정답에 해당하는 신경망의 출력만으로 교차 엔트로피 오차를 계산할 수 있다는 것이 핵심.\n",
    "# 따라서 y[np.arange(batch_size), t]로 한 것이다.\n",
    "# batch_size가 5, t=[2, 7, 0, 9, 4]라면?\n",
    "# np.arange(batch_size, t)\n",
    "# == y[np.arange([0, 1, 2, 3, 4]), [2, 7, 0, 9, 4]]]\n",
    "# == [y[0, 2], y[1, 7], y[2, 0], y[3, 9], y[4, 4]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
